{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-11-16T18:50:46.749580Z",
     "iopub.status.busy": "2025-11-16T18:50:46.749296Z",
     "iopub.status.idle": "2025-11-16T18:50:47.148892Z",
     "shell.execute_reply": "2025-11-16T18:50:47.148326Z",
     "shell.execute_reply.started": "2025-11-16T18:50:46.749559Z"
    },
    "id": "3rwptix5kGK9",
    "outputId": "64d040d1-03a6-48c7-c89b-c50e44bdcb16",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /kaggle/input/\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"bitext/bitext-gen-ai-chatbot-customer-support-dataset\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aca72b23"
   },
   "source": [
    "## Summary:\n",
    "\n",
    "### Q&A\n",
    "Yes, the dataset has been successfully loaded into the `df` DataFrame.\n",
    "\n",
    "### Data Analysis Key Findings\n",
    "*   The primary CSV file, `Bitext_Sample_Customer_Support_Training_Dataset_27K_responses-v11.csv`, was successfully identified and loaded into a pandas DataFrame named `df`.\n",
    "*   The DataFrame `df` contains columns such as 'flags', 'instruction', 'category', 'intent', and 'response', as verified by displaying its head.\n",
    "\n",
    "### Insights or Next Steps\n",
    "*   The loaded DataFrame `df` is now ready for further data exploration, cleaning, and analysis to understand the customer support interactions.\n",
    "*   A logical next step would be to perform a quick data overview, including checking data types, missing values, and unique values in categorical columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 349
    },
    "execution": {
     "iopub.execute_input": "2025-11-16T18:50:47.150224Z",
     "iopub.status.busy": "2025-11-16T18:50:47.149914Z",
     "iopub.status.idle": "2025-11-16T18:50:47.839125Z",
     "shell.execute_reply": "2025-11-16T18:50:47.838395Z",
     "shell.execute_reply.started": "2025-11-16T18:50:47.150206Z"
    },
    "id": "427aa5eb",
    "outputId": "730c2f64-b51f-4ff5-9bac-afeb15ce89e1",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files available in the dataset directory: ['Bitext_Sample_Customer_Support_Training_Dataset_27K_responses-v11.csv']\n",
      "Successfully loaded 'Bitext_Sample_Customer_Support_Training_Dataset_27K_responses-v11.csv' into DataFrame 'df'.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>flags</th>\n",
       "      <th>instruction</th>\n",
       "      <th>category</th>\n",
       "      <th>intent</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B</td>\n",
       "      <td>question about cancelling order {{Order Number}}</td>\n",
       "      <td>ORDER</td>\n",
       "      <td>cancel_order</td>\n",
       "      <td>I've understood you have a question regarding ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BQZ</td>\n",
       "      <td>i have a question about cancelling oorder {{Or...</td>\n",
       "      <td>ORDER</td>\n",
       "      <td>cancel_order</td>\n",
       "      <td>I've been informed that you have a question ab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BLQZ</td>\n",
       "      <td>i need help cancelling puchase {{Order Number}}</td>\n",
       "      <td>ORDER</td>\n",
       "      <td>cancel_order</td>\n",
       "      <td>I can sense that you're seeking assistance wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BL</td>\n",
       "      <td>I need to cancel purchase {{Order Number}}</td>\n",
       "      <td>ORDER</td>\n",
       "      <td>cancel_order</td>\n",
       "      <td>I understood that you need assistance with can...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BCELN</td>\n",
       "      <td>I cannot afford this order, cancel purchase {{...</td>\n",
       "      <td>ORDER</td>\n",
       "      <td>cancel_order</td>\n",
       "      <td>I'm sensitive to the fact that you're facing f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   flags                                        instruction category  \\\n",
       "0      B   question about cancelling order {{Order Number}}    ORDER   \n",
       "1    BQZ  i have a question about cancelling oorder {{Or...    ORDER   \n",
       "2   BLQZ    i need help cancelling puchase {{Order Number}}    ORDER   \n",
       "3     BL         I need to cancel purchase {{Order Number}}    ORDER   \n",
       "4  BCELN  I cannot afford this order, cancel purchase {{...    ORDER   \n",
       "\n",
       "         intent                                           response  \n",
       "0  cancel_order  I've understood you have a question regarding ...  \n",
       "1  cancel_order  I've been informed that you have a question ab...  \n",
       "2  cancel_order  I can sense that you're seeking assistance wit...  \n",
       "3  cancel_order  I understood that you need assistance with can...  \n",
       "4  cancel_order  I'm sensitive to the fact that you're facing f...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# List files in the dataset directory\n",
    "files_in_path = os.listdir(path)\n",
    "print(f\"Files available in the dataset directory: {files_in_path}\")\n",
    "\n",
    "# Identify the main CSV file. Based on previous runs or common dataset structures,\n",
    "# it's often 'Bitext_Sample_-_es_to_en_-_Sheet1.csv'\n",
    "# Let's try to find a .csv file or assume the given name.\n",
    "csv_file_name = None\n",
    "for file in files_in_path:\n",
    "    if file.endswith('.csv'):\n",
    "        csv_file_name = file\n",
    "        break\n",
    "\n",
    "if csv_file_name is None:\n",
    "    print(\"No CSV file found in the dataset directory. Attempting to use a known filename.\")\n",
    "    # Fallback to a known filename if no CSV is automatically detected\n",
    "    csv_file_name = 'Bitext_Sample_-_es_to_en_-_Sheet1.csv'\n",
    "\n",
    "csv_file_path = os.path.join(path, csv_file_name)\n",
    "\n",
    "# Load the CSV file into a pandas DataFrame\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "print(f\"Successfully loaded '{csv_file_name}' into DataFrame 'df'.\")\n",
    "\n",
    "# Display the head of the DataFrame to verify\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jZsJXRRumM3N"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-11-16T18:50:47.839974Z",
     "iopub.status.busy": "2025-11-16T18:50:47.839768Z",
     "iopub.status.idle": "2025-11-16T18:50:47.866327Z",
     "shell.execute_reply": "2025-11-16T18:50:47.865494Z",
     "shell.execute_reply.started": "2025-11-16T18:50:47.839957Z"
    },
    "id": "77DDZcSQmGAo",
    "outputId": "d505e32f-05f7-4953-dc15-c024f94e741e",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 26872 entries, 0 to 26871\n",
      "Data columns (total 5 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   flags        26872 non-null  object\n",
      " 1   instruction  26872 non-null  object\n",
      " 2   category     26872 non-null  object\n",
      " 3   intent       26872 non-null  object\n",
      " 4   response     26872 non-null  object\n",
      "dtypes: object(5)\n",
      "memory usage: 1.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-11-16T18:50:47.867336Z",
     "iopub.status.busy": "2025-11-16T18:50:47.867115Z",
     "iopub.status.idle": "2025-11-16T18:50:47.904363Z",
     "shell.execute_reply": "2025-11-16T18:50:47.903785Z",
     "shell.execute_reply.started": "2025-11-16T18:50:47.867310Z"
    },
    "id": "b853fda6",
    "outputId": "bfdd483f-8789-4c14-d927-f07ce733cae6",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique placeholders found:\n",
      "Account Category\n",
      "Account Type\n",
      "Currency Symbol\n",
      "Delivery City\n",
      "Delivery Country\n",
      "Invoice Number\n",
      "Order Number\n",
      "Person Name\n",
      "Refund Amount\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import random\n",
    "\n",
    "\n",
    "\n",
    "# Define the regex pattern for placeholders\n",
    "placeholder_pattern = r\"\\{\\{([^}]+)\\}\\}\"\n",
    "\n",
    "# Initialize a set to store unique placeholders\n",
    "unique_placeholders = set()\n",
    "\n",
    "# Iterate through the 'instruction' column and extract placeholders\n",
    "if 'instruction' in df.columns:\n",
    "    for instruction_text in df['instruction'].astype(str):\n",
    "        matches = re.findall(placeholder_pattern, instruction_text)\n",
    "        for match in matches:\n",
    "            unique_placeholders.add(match.strip())\n",
    "\n",
    "    print(\"Unique placeholders found:\")\n",
    "    for placeholder in sorted(list(unique_placeholders)):\n",
    "        print(placeholder)\n",
    "else:\n",
    "    print(\"The 'instruction' column does not exist in the DataFrame.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 244
    },
    "execution": {
     "iopub.execute_input": "2025-11-16T18:50:47.906353Z",
     "iopub.status.busy": "2025-11-16T18:50:47.906164Z",
     "iopub.status.idle": "2025-11-16T18:50:48.522343Z",
     "shell.execute_reply": "2025-11-16T18:50:48.521806Z",
     "shell.execute_reply.started": "2025-11-16T18:50:47.906338Z"
    },
    "id": "b5a1a226",
    "outputId": "a9ffea6f-9118-4115-ecf1-9102beec9c0d",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instructions with synthetic values generated successfully. Displaying original and synthetic instructions for verification:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instruction</th>\n",
       "      <th>instruction_synthetic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>question about cancelling order {{Order Number}}</td>\n",
       "      <td>question about cancelling order ORD-2025-12345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i have a question about cancelling oorder {{Or...</td>\n",
       "      <td>i have a question about cancelling oorder ORD-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i need help cancelling puchase {{Order Number}}</td>\n",
       "      <td>i need help cancelling puchase ORD-2025-12345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I need to cancel purchase {{Order Number}}</td>\n",
       "      <td>I need to cancel purchase ORD-2025-12345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I cannot afford this order, cancel purchase {{...</td>\n",
       "      <td>I cannot afford this order, cancel purchase OR...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         instruction  \\\n",
       "0   question about cancelling order {{Order Number}}   \n",
       "1  i have a question about cancelling oorder {{Or...   \n",
       "2    i need help cancelling puchase {{Order Number}}   \n",
       "3         I need to cancel purchase {{Order Number}}   \n",
       "4  I cannot afford this order, cancel purchase {{...   \n",
       "\n",
       "                               instruction_synthetic  \n",
       "0     question about cancelling order ORD-2025-12345  \n",
       "1  i have a question about cancelling oorder ORD-...  \n",
       "2      i need help cancelling puchase ORD-2025-12345  \n",
       "3           I need to cancel purchase ORD-2025-12345  \n",
       "4  I cannot afford this order, cancel purchase OR...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Define the mapping of placeholders to synthetic values\n",
    "synthetic_values = {\n",
    "    \"Order Number\": \"ORD-2025-12345\",\n",
    "    \"Person Name\": \"Maria Garcia\",\n",
    "    \"email\": \"alex.smith@example.com\", # Assuming 'email' is a placeholder\n",
    "    \"product_name\": \"Wireless Mouse\", # Assuming 'product_name' is a placeholder\n",
    "    \"date\": \"05/09/2025\", # Assuming 'date' is a placeholder\n",
    "    \"Refund Amount\": \"$50.00\", # Based on previously found placeholders\n",
    "    \"Account Category\": \"Savings\", # Based on previously found placeholders\n",
    "    \"Account Type\": \"Checking\", # Based on previously found placeholders\n",
    "    \"Currency Symbol\": \"$\", # Based on previously found placeholders\n",
    "    \"Delivery City\": \"New York\", # Based on previously found placeholders\n",
    "    \"Delivery Country\": \"USA\", # Based on previously found placeholders\n",
    "    \"Invoice Number\": \"INV-2025-54321\", # Based on previously found placeholders\n",
    "}\n",
    "\n",
    "# Create a copy of the DataFrame to store the modified instructions\n",
    "df_synthetic = df.copy()\n",
    "\n",
    "# Function to replace placeholders\n",
    "def replace_placeholders(text):\n",
    "    for placeholder, value in synthetic_values.items():\n",
    "        # Use re.escape to handle special characters in placeholder names\n",
    "        text = re.sub(r'\\{\\{' + re.escape(placeholder) + r'\\}\\}', value, text, flags=re.IGNORECASE)\n",
    "    return text\n",
    "\n",
    "# Apply the replacement function to the 'instruction' column\n",
    "if 'instruction' in df_synthetic.columns:\n",
    "    df_synthetic['instruction_synthetic'] = df_synthetic['instruction'].apply(replace_placeholders)\n",
    "    print(\"Instructions with synthetic values generated successfully. Displaying original and synthetic instructions for verification:\")\n",
    "    display(df_synthetic[['instruction', 'instruction_synthetic']].head())\n",
    "else:\n",
    "    print(\"The 'instruction' column does not exist in the DataFrame.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-11-16T18:50:48.523155Z",
     "iopub.status.busy": "2025-11-16T18:50:48.522960Z",
     "iopub.status.idle": "2025-11-16T18:50:48.540332Z",
     "shell.execute_reply": "2025-11-16T18:50:48.539730Z",
     "shell.execute_reply.started": "2025-11-16T18:50:48.523140Z"
    },
    "id": "exxc9K33m9MG",
    "outputId": "77a4fc8e-0b6b-4682-ca75-d9303e6c1fca",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 26872 entries, 0 to 26871\n",
      "Data columns (total 6 columns):\n",
      " #   Column                 Non-Null Count  Dtype \n",
      "---  ------                 --------------  ----- \n",
      " 0   flags                  26872 non-null  object\n",
      " 1   instruction            26872 non-null  object\n",
      " 2   category               26872 non-null  object\n",
      " 3   intent                 26872 non-null  object\n",
      " 4   response               26872 non-null  object\n",
      " 5   instruction_synthetic  26872 non-null  object\n",
      "dtypes: object(6)\n",
      "memory usage: 1.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df_synthetic.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 712
    },
    "execution": {
     "iopub.execute_input": "2025-11-16T18:50:48.541320Z",
     "iopub.status.busy": "2025-11-16T18:50:48.541133Z",
     "iopub.status.idle": "2025-11-16T18:50:48.562534Z",
     "shell.execute_reply": "2025-11-16T18:50:48.561975Z",
     "shell.execute_reply.started": "2025-11-16T18:50:48.541305Z"
    },
    "id": "1d927787",
    "outputId": "8f0c36dd-36e4-47e9-a9b8-5dc1395f6add",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling 20 processed rows for verification:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instruction</th>\n",
       "      <th>instruction_synthetic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9329</th>\n",
       "      <td>I can't talk with  a human agent</td>\n",
       "      <td>I can't talk with  a human agent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4160</th>\n",
       "      <td>I have got to locate hte bills from {{Person N...</td>\n",
       "      <td>I have got to locate hte bills from Maria Garcia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18500</th>\n",
       "      <td>I cannot pay, help me to inform of a problem w...</td>\n",
       "      <td>I cannot pay, help me to inform of a problem w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8840</th>\n",
       "      <td>I want help speaking to customer service</td>\n",
       "      <td>I want help speaking to customer service</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5098</th>\n",
       "      <td>I try to see th accepted payment options</td>\n",
       "      <td>I try to see th accepted payment options</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17250</th>\n",
       "      <td>where to sign up to the company nmewsletter</td>\n",
       "      <td>where to sign up to the company nmewsletter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3589</th>\n",
       "      <td>I'd like to see the withdrwaal fee how can i d...</td>\n",
       "      <td>I'd like to see the withdrwaal fee how can i d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9043</th>\n",
       "      <td>I want to speak with someone</td>\n",
       "      <td>I want to speak with someone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15800</th>\n",
       "      <td>can you help me getting bill #85632?</td>\n",
       "      <td>can you help me getting bill #85632?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4384</th>\n",
       "      <td>I don't know how to take a quick look at invoi...</td>\n",
       "      <td>I don't know how to take a quick look at invoi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11150</th>\n",
       "      <td>I don't know how to delete my platinum account</td>\n",
       "      <td>I don't know how to delete my platinum account</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6417</th>\n",
       "      <td>help me check in what cases can I ask to be re...</td>\n",
       "      <td>help me check in what cases can I ask to be re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4186</th>\n",
       "      <td>is it possible to locate my bill from {{Person...</td>\n",
       "      <td>is it possible to locate my bill from Maria Ga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7301</th>\n",
       "      <td>i want help to file a consumer claim against u...</td>\n",
       "      <td>i want help to file a consumer claim against u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8267</th>\n",
       "      <td>uhave a free number to call customer support</td>\n",
       "      <td>uhave a free number to call customer support</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3798</th>\n",
       "      <td>i do not know how i can see the early terminat...</td>\n",
       "      <td>i do not know how i can see the early terminat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17355</th>\n",
       "      <td>could you help me to unsubscribe to the damn n...</td>\n",
       "      <td>could you help me to unsubscribe to the damn n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21099</th>\n",
       "      <td>I don't know how to inform of problems with a ...</td>\n",
       "      <td>I don't know how to inform of problems with a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15331</th>\n",
       "      <td>download bill from {{Person Name}}</td>\n",
       "      <td>download bill from Maria Garcia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15938</th>\n",
       "      <td>want assistance receiving a refund of money</td>\n",
       "      <td>want assistance receiving a refund of money</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             instruction  \\\n",
       "9329                    I can't talk with  a human agent   \n",
       "4160   I have got to locate hte bills from {{Person N...   \n",
       "18500  I cannot pay, help me to inform of a problem w...   \n",
       "8840            I want help speaking to customer service   \n",
       "5098            I try to see th accepted payment options   \n",
       "17250        where to sign up to the company nmewsletter   \n",
       "3589   I'd like to see the withdrwaal fee how can i d...   \n",
       "9043                        I want to speak with someone   \n",
       "15800               can you help me getting bill #85632?   \n",
       "4384   I don't know how to take a quick look at invoi...   \n",
       "11150     I don't know how to delete my platinum account   \n",
       "6417   help me check in what cases can I ask to be re...   \n",
       "4186   is it possible to locate my bill from {{Person...   \n",
       "7301   i want help to file a consumer claim against u...   \n",
       "8267        uhave a free number to call customer support   \n",
       "3798   i do not know how i can see the early terminat...   \n",
       "17355  could you help me to unsubscribe to the damn n...   \n",
       "21099  I don't know how to inform of problems with a ...   \n",
       "15331                 download bill from {{Person Name}}   \n",
       "15938        want assistance receiving a refund of money   \n",
       "\n",
       "                                   instruction_synthetic  \n",
       "9329                    I can't talk with  a human agent  \n",
       "4160    I have got to locate hte bills from Maria Garcia  \n",
       "18500  I cannot pay, help me to inform of a problem w...  \n",
       "8840            I want help speaking to customer service  \n",
       "5098            I try to see th accepted payment options  \n",
       "17250        where to sign up to the company nmewsletter  \n",
       "3589   I'd like to see the withdrwaal fee how can i d...  \n",
       "9043                        I want to speak with someone  \n",
       "15800               can you help me getting bill #85632?  \n",
       "4384   I don't know how to take a quick look at invoi...  \n",
       "11150     I don't know how to delete my platinum account  \n",
       "6417   help me check in what cases can I ask to be re...  \n",
       "4186   is it possible to locate my bill from Maria Ga...  \n",
       "7301   i want help to file a consumer claim against u...  \n",
       "8267        uhave a free number to call customer support  \n",
       "3798   i do not know how i can see the early terminat...  \n",
       "17355  could you help me to unsubscribe to the damn n...  \n",
       "21099  I don't know how to inform of problems with a ...  \n",
       "15331                    download bill from Maria Garcia  \n",
       "15938        want assistance receiving a refund of money  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if 'instruction_synthetic' in df_synthetic.columns:\n",
    "    print(\"Sampling 20 processed rows for verification:\")\n",
    "    display(df_synthetic[['instruction', 'instruction_synthetic']].sample(n=20, random_state=42))\n",
    "else:\n",
    "    print(\"The 'instruction_synthetic' column does not exist in the DataFrame. Please ensure the placeholder replacement step was executed correctly.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "execution": {
     "iopub.execute_input": "2025-11-16T18:50:48.563398Z",
     "iopub.status.busy": "2025-11-16T18:50:48.563180Z",
     "iopub.status.idle": "2025-11-16T18:50:49.197867Z",
     "shell.execute_reply": "2025-11-16T18:50:49.197096Z",
     "shell.execute_reply.started": "2025-11-16T18:50:48.563372Z"
    },
    "id": "8d92ece6",
    "outputId": "912437da-1bac-429b-8acd-4dd1a0f23644",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 21497 samples\n",
      "Validation set size: 2687 samples\n",
      "Test set size: 2688 samples\n",
      "\n",
      "Head of X_train:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>flags</th>\n",
       "      <th>category</th>\n",
       "      <th>instruction_synthetic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18407</th>\n",
       "      <td>BL</td>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>I want assistance informing of a trouble with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4878</th>\n",
       "      <td>BKL</td>\n",
       "      <td>INVOICE</td>\n",
       "      <td>see bill #12588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26858</th>\n",
       "      <td>BCL</td>\n",
       "      <td>REFUND</td>\n",
       "      <td>I want to see my refund current status, help me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25464</th>\n",
       "      <td>BKL</td>\n",
       "      <td>ORDER</td>\n",
       "      <td>see current status of order ORD-2025-12345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12237</th>\n",
       "      <td>BCIL</td>\n",
       "      <td>DELIVERY</td>\n",
       "      <td>I need to check the options for shipping, how ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      flags  category                              instruction_synthetic\n",
       "18407    BL   PAYMENT  I want assistance informing of a trouble with ...\n",
       "4878    BKL   INVOICE                                    see bill #12588\n",
       "26858   BCL    REFUND    I want to see my refund current status, help me\n",
       "25464   BKL     ORDER         see current status of order ORD-2025-12345\n",
       "12237  BCIL  DELIVERY  I need to check the options for shipping, how ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Drop the original 'instruction' column and keep 'instruction_synthetic'\n",
    "if 'instruction' in df_synthetic.columns:\n",
    "    df_synthetic = df_synthetic.drop(columns=['instruction'])\n",
    "\n",
    "# Define the features (X) and target (y) for intent classification\n",
    "X = df_synthetic.drop(columns=['response', 'intent']) # Features should not include the target or the response\n",
    "y = df_synthetic['intent'] # Target is the 'intent' column\n",
    "\n",
    "# First split: 80% train, 20% (validation + test)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Second split: 50% validation, 50% test from the 20% temporary set\n",
    "# This results in 10% validation and 10% test from the original dataset\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n",
    "\n",
    "print(f\"Training set size: {len(X_train)} samples\")\n",
    "print(f\"Validation set size: {len(X_val)} samples\")\n",
    "print(f\"Test set size: {len(X_test)} samples\")\n",
    "\n",
    "# Display the head of the training set features as an example\n",
    "print(\"\\nHead of X_train:\")\n",
    "display(X_train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G4rJhpJjvkTh"
   },
   "source": [
    "Projects Goal is to -\n",
    "Build, evaluate, and compare two modeling pathways for intent classification â€”\n",
    "LLM-based zero/few-shot inference and fine-tuned transformers; both using uniform\n",
    "evaluation metrics (Accuracy, Macro-F1, and Cost)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4VKEH_tvwEX2"
   },
   "source": [
    "Approach 1: Zero- or Few-Shot via Large Language Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "870nRX1-pGrE"
   },
   "source": [
    "Sample Test Data for LLM Experiments: Sample up to 10 examples from each unique intent class from the X_test and y_test datasets, storing them in X_test_sampled and y_test_sampled respectively. This ensures a controlled and representative dataset for LLM experiments while managing API costs.\n",
    "\n",
    "Define Zero-Shot Prompt Structure: Create a Python function to construct the zero-shot prompt for the LLM. This prompt will use the combined_instruction from the sampled data and explicitly instruct the LLM to classify the intent, potentially listing the available intent classes to guide its response.\n",
    "\n",
    "Implement LLM Inference Function: Provide a placeholder or example function that demonstrates how to make an LLM API call (e.g., using OpenAI's API client). This function will take a prompt and return the LLM's response. It will also include guidance for the user to insert their actual API key and handle the specific API integration for their chosen LLM, emphasizing careful usage to manage costs.\n",
    "\n",
    "Run LLM Inference and Collect Predictions: Iterate through the sampled test data, generate a zero-shot prompt for each entry, call the LLM inference function to get a prediction, and collect all predicted intents. This step will also include parsing the LLM's response to extract the intent label.\n",
    "\n",
    "Evaluate LLM Performance: Calculate and display the Accuracy and Macro-F1 scores by comparing the collected LLM predictions against the true intent labels from the sampled test data. This will provide the initial performance metrics for the zero-shot approach.\n",
    "\n",
    "Final Task: Summarize the results of the zero-shot LLM intent classification and prepare for the next steps, potentially exploring few-shot examples or moving to the fine-tuned transformer approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1fbdaf1e"
   },
   "source": [
    "\n",
    "\n",
    "# Task\n",
    "Prepare the LLM environment, sample 10 examples from each unique intent class from `X_test` and `y_test` for LLM experiments, and then implement a zero-shot intent classification workflow. This workflow should include defining a prompt structure using `combined_instruction`, developing a function for LLM inference, running the inference to collect predictions, and finally evaluating the LLM's performance using Accuracy and Macro-F1 scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "927c8471"
   },
   "source": [
    "## Prepare LLM Environment and Sample Data\n",
    "\n",
    "### Subtask:\n",
    "Guide the user to set up their chosen LLM API key (e.g., as an environment variable) and then sample 10 examples from each unique intent class from the `X_test` and `y_test` datasets. This sampled data will be used for all LLM experiments to control costs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a800a45e"
   },
   "source": [
    "**Reasoning**:\n",
    "Now that the instructions for setting up the API key are provided, the next step is to implement the sampling logic. This involves identifying unique intents, sampling up to 10 examples per intent from the test sets, and combining them into new sampled DataFrames for features and labels.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "974297bf"
   },
   "source": [
    "# Task\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Ensure 'intent' column is available in X_test for sampling\n",
    "if 'intent' not in X_test.columns:\n",
    "    print(\"Error: 'intent' column not found in X_test. Please ensure it's present for stratified sampling.\")\n",
    "else:\n",
    "    # Get unique intent classes\n",
    "    unique_intents = X_test['intent'].unique()\n",
    "    print(f\"Found {len(unique_intents)} unique intent classes.\")\n",
    "\n",
    "    X_test_sampled_list = []\n",
    "    y_test_sampled_list = []\n",
    "\n",
    "    # Iterate through each unique intent to sample examples\n",
    "    for intent_class in unique_intents:\n",
    "        # Filter X_test and y_test for the current intent class\n",
    "        X_intent = X_test[X_test['intent'] == intent_class]\n",
    "        y_intent = y_test[X_test['intent'] == intent_class] # y_test should align with X_test indices\n",
    "\n",
    "        # Sample up to 10 examples from the current intent class\n",
    "        # Use min(len(X_intent), 10) to handle classes with fewer than 10 examples\n",
    "        if not X_intent.empty:\n",
    "            sampled_indices = X_intent.sample(n=min(len(X_intent), 10), random_state=42).index\n",
    "            X_test_sampled_list.append(X_test.loc[sampled_indices])\n",
    "            y_test_sampled_list.append(y_test.loc[sampled_indices])\n",
    "\n",
    "    # Concatenate all sampled data into new DataFrames\n",
    "    X_test_sampled = pd.concat(X_test_sampled_list)\n",
    "    y_test_sampled = pd.concat(y_test_sampled_list)\n",
    "\n",
    "    print(f\"\\nTotal sampled examples: {len(X_test_sampled)}\")\n",
    "    print(f\"Number of unique intents in sampled data: {X_test_sampled['intent'].nunique()}\")\n",
    "\n",
    "    print(\"\\nHead of X_test_sampled:\")\n",
    "    display(X_test_sampled.head())\n",
    "\n",
    "    print(\"\\nValue counts for 'intent' in X_test_sampled to verify distribution:\")\n",
    "    display(X_test_sampled['intent'].value_counts())\n",
    "\n",
    "    print(\"\\nHead of y_test_sampled:\")\n",
    "    display(y_test_sampled.head())\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CFuAsc50oj5U"
   },
   "source": [
    "Sample Test Data for LLM Experiments: Sample up to 10 examples from each unique intent class from the X_test and y_test datasets, storing them in X_test_sampled and y_test_sampled respectively. This ensures a controlled and representative dataset for LLM experiments while managing API costs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mKy6SJgtlXnw"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Y4NFAAZlJnb"
   },
   "source": [
    "We removed 'intent' and 'Respone' from X, should category be also removed or would it be data leakage? What is Data Leakage? Data leakage occurs when information from outside the training dataset is used to create the model, leading to overly optimistic performance estimates. In classification tasks, this often happens when a feature directly or indirectly reveals the target variable.\n",
    "\n",
    "The 'category' Column in our X Features: Currently, the X features (which are used to construct the combined_instruction for the LLM prompt) include flags, category, and instruction_synthetic. So, yes, the category column is being fed to the LLM as part of the input prompt.\n",
    "\n",
    "Does 'category' cause leakage here? It could lead to a form of leakage if the 'category' is a direct, one-to-one mapping with the 'intent'. For example, if there's only one intent per category, then knowing the category directly tells you the intent.\n",
    "\n",
    "However, in many real-world scenarios (and seemingly in this dataset based on the examples), 'category' provides broader context (e.g., 'ORDER' category can contain intents like cancel_order, track_order, change_order). In such cases, category acts as a helpful contextual feature that allows the LLM to narrow down the possibilities without explicitly revealing the exact intent. When building a prompt for an LLM, providing relevant contextual information like the category is often beneficial for its reasoning.\n",
    "\n",
    "For the purpose of evaluating the zero-shot LLM's ability to classify intent given this context, including 'category' in the prompt is a reasonable approach to provide the LLM with sufficient information to make its prediction. If we were building a traditional machine learning model from scratch and trying to predict intent purely from the instruction_synthetic without any pre-categorization, we would need to carefully analyze the correlation between 'category' and 'intent' to decide if 'category' should be an independent feature or if it leads to excessive leakage.\n",
    "\n",
    "For now, we'll continue using category as a contextual element in the LLM prompt, as it is a common practice to provide LLMs with as much relevant input as possible to guide their zero-shot reasoning.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "execution": {
     "iopub.execute_input": "2025-11-16T18:50:49.199236Z",
     "iopub.status.busy": "2025-11-16T18:50:49.198765Z",
     "iopub.status.idle": "2025-11-16T18:50:49.248158Z",
     "shell.execute_reply": "2025-11-16T18:50:49.247605Z",
     "shell.execute_reply.started": "2025-11-16T18:50:49.199210Z"
    },
    "id": "oAQrhNE5nucO",
    "outputId": "47cd5784-c04f-4db3-d633-1647c62e6e4c",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 27 unique intent classes.\n",
      "\n",
      "Total sampled examples: 270\n",
      "Number of unique intents in sampled data: 27\n",
      "\n",
      "Head of X_test_sampled:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>flags</th>\n",
       "      <th>category</th>\n",
       "      <th>instruction_synthetic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1267</th>\n",
       "      <td>BLQZ</td>\n",
       "      <td>ORDER</td>\n",
       "      <td>i have got to swap  an item of order ORD-2025-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1179</th>\n",
       "      <td>BIL</td>\n",
       "      <td>ORDER</td>\n",
       "      <td>how do I correct purchase ORD-2025-12345?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1310</th>\n",
       "      <td>BILZ</td>\n",
       "      <td>ORDER</td>\n",
       "      <td>canm you help me to update purchase ORD-2025-1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048</th>\n",
       "      <td>BLMQ</td>\n",
       "      <td>ORDER</td>\n",
       "      <td>i try to switch several items of order ORD-202...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1950</th>\n",
       "      <td>BL</td>\n",
       "      <td>ORDER</td>\n",
       "      <td>I need information about correcting purchase O...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     flags category                              instruction_synthetic\n",
       "1267  BLQZ    ORDER  i have got to swap  an item of order ORD-2025-...\n",
       "1179   BIL    ORDER          how do I correct purchase ORD-2025-12345?\n",
       "1310  BILZ    ORDER  canm you help me to update purchase ORD-2025-1...\n",
       "1048  BLMQ    ORDER  i try to switch several items of order ORD-202...\n",
       "1950    BL    ORDER  I need information about correcting purchase O..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Value counts for 'intent' in y_test_sampled to verify distribution:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "intent\n",
       "change_order                10\n",
       "newsletter_subscription     10\n",
       "review                      10\n",
       "track_refund                10\n",
       "delivery_options            10\n",
       "create_account              10\n",
       "delivery_period             10\n",
       "contact_human_agent         10\n",
       "payment_issue               10\n",
       "complaint                   10\n",
       "check_cancellation_fee      10\n",
       "set_up_shipping_address     10\n",
       "track_order                 10\n",
       "cancel_order                10\n",
       "edit_account                10\n",
       "recover_password            10\n",
       "get_invoice                 10\n",
       "switch_account              10\n",
       "registration_problems       10\n",
       "contact_customer_service    10\n",
       "place_order                 10\n",
       "change_shipping_address     10\n",
       "check_invoice               10\n",
       "get_refund                  10\n",
       "check_refund_policy         10\n",
       "check_payment_methods       10\n",
       "delete_account              10\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Head of y_test_sampled:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1267    change_order\n",
       "1179    change_order\n",
       "1310    change_order\n",
       "1048    change_order\n",
       "1950    change_order\n",
       "Name: intent, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# The 'intent' column is the target variable y_test, not in X_test.\n",
    "# We need to sample based on y_test and then use the sampled indices to get corresponding X_test rows.\n",
    "\n",
    "# Get unique intent classes from y_test\n",
    "unique_intents = y_test.unique()\n",
    "print(f\"Found {len(unique_intents)} unique intent classes.\")\n",
    "\n",
    "X_test_sampled_list = []\n",
    "y_test_sampled_list = []\n",
    "\n",
    "# Iterate through each unique intent to sample examples\n",
    "for intent_class in unique_intents:\n",
    "    # Filter y_test for the current intent class to get its indices\n",
    "    intent_indices = y_test[y_test == intent_class].index\n",
    "\n",
    "    # Sample up to 10 indices from the current intent class\n",
    "    # Use min(len(intent_indices), 10) to handle classes with fewer than 10 examples\n",
    "    if not intent_indices.empty:\n",
    "        # Sample indices directly from the filtered indices\n",
    "        sampled_indices = intent_indices.to_series().sample(n=min(len(intent_indices), 10), random_state=42).index\n",
    "        X_test_sampled_list.append(X_test.loc[sampled_indices])\n",
    "        y_test_sampled_list.append(y_test.loc[sampled_indices])\n",
    "\n",
    "# Concatenate all sampled data into new DataFrames\n",
    "X_test_sampled = pd.concat(X_test_sampled_list)\n",
    "y_test_sampled = pd.concat(y_test_sampled_list)\n",
    "\n",
    "print(f\"\\nTotal sampled examples: {len(X_test_sampled)}\")\n",
    "print(f\"Number of unique intents in sampled data: {y_test_sampled.nunique()}\") # Check unique intents in y_test_sampled\n",
    "\n",
    "print(\"\\nHead of X_test_sampled:\")\n",
    "display(X_test_sampled.head())\n",
    "\n",
    "print(\"\\nValue counts for 'intent' in y_test_sampled to verify distribution:\")\n",
    "display(y_test_sampled.value_counts()) # Display value counts from y_test_sampled\n",
    "\n",
    "print(\"\\nHead of y_test_sampled:\")\n",
    "display(y_test_sampled.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ahFd6Abck9f9"
   },
   "source": [
    "Unique Intents Found: We identified all 27 unique intent classes from your y_test dataset.\n",
    "Total Sampled Examples: A total of 270 examples have been sampled.\n",
    "Stratified Sampling: As intended, the value_counts for y_test_sampled confirms that we have exactly 10 samples for each of the 27 unique intent classes, ensuring a balanced representation for LLM evaluation.\n",
    "This means our sampled dataset is now perfectly prepared for the next step: defining the zero-shot prompt structure for the LLM!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ie6lImioo3d5"
   },
   "source": [
    "Let's redefine the zero-shot prompt structure. This updated prompt will explicitly instruct the LLM to identify the intent from the customer query and provide the list of possible intent categories it should choose from. After the modification, I will show an example of the generated prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-11-17T04:10:57.055072Z",
     "iopub.status.busy": "2025-11-17T04:10:57.054487Z",
     "iopub.status.idle": "2025-11-17T04:10:57.063004Z",
     "shell.execute_reply": "2025-11-17T04:10:57.062269Z",
     "shell.execute_reply.started": "2025-11-17T04:10:57.055052Z"
    },
    "id": "a15911b8",
    "outputId": "c16225c8-e0ef-435d-d3bd-6d490de02d45",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All unique intents available (formatted for prompt): \n",
      "- cancel_order\n",
      "- change_order\n",
      "- change_shipping_address\n",
      "- check_cancellation_fee\n",
      "- check_invoice\n",
      "- check_payment_methods\n",
      "- check_refund_policy\n",
      "- complaint\n",
      "- contact_customer_service\n",
      "- contact_human_agent\n",
      "- create_account\n",
      "- delete_account\n",
      "- delivery_options\n",
      "- delivery_period\n",
      "- edit_account\n",
      "- get_invoice\n",
      "- get_refund\n",
      "- newsletter_subscription\n",
      "- payment_issue\n",
      "- place_order\n",
      "- recover_password\n",
      "- registration_problems\n",
      "- review\n",
      "- set_up_shipping_address\n",
      "- switch_account\n",
      "- track_order\n",
      "- track_refund\n",
      "\n",
      "Example Zero-Shot Prompt (improved):\n",
      "\n",
      "You are an intent classification system.\n",
      "Your task is to classify the intent of a customer query.\n",
      "\n",
      "Specific guidelines (but not rules)\n",
      "\n",
      "Customers expecting a refund is not inherently getting a refund. They may be expecting one.\n",
      "Customers asking to check when their order will arrive are asking about the delivery period - unless an order number is apart of the instruction.\n",
      "Customers asking about possibility of orders are asking about delivery options, including where they are ordering from.\n",
      "Customers asking setting up a new or secondary address are not editing their address, but setting up an address.\n",
      "Customers looking to use a specific account (such as chequing and savings) or profile, are attempting to switch accounts.\n",
      "Customers looking customer assistance aren't inherently looking for human assistance.\n",
      "If an invoice has already been issued, and the customer is looking for it, that is check_invoice. \n",
      "Refund policy questions relate to check_refund_policy. Note that if they aren't asking for specifics on the policy, they are likely just wanting to get a refund.\n",
      "\n",
      "\n",
      "Customer Query Details:\n",
      "- Category: ORDER\n",
      "- User Instruction: i have got to swap  an item of order ORD-2025-12345\n",
      "\n",
      "You MUST choose exactly one intent ONLY from the following list:\n",
      "\n",
      "Available Intents:\n",
      "\n",
      "- cancel_order\n",
      "- change_order\n",
      "- change_shipping_address\n",
      "- check_cancellation_fee\n",
      "- check_invoice\n",
      "- check_payment_methods\n",
      "- check_refund_policy\n",
      "- complaint\n",
      "- contact_customer_service\n",
      "- contact_human_agent\n",
      "- create_account\n",
      "- delete_account\n",
      "- delivery_options\n",
      "- delivery_period\n",
      "- edit_account\n",
      "- get_invoice\n",
      "- get_refund\n",
      "- newsletter_subscription\n",
      "- payment_issue\n",
      "- place_order\n",
      "- recover_password\n",
      "- registration_problems\n",
      "- review\n",
      "- set_up_shipping_address\n",
      "- switch_account\n",
      "- track_order\n",
      "- track_refund\n",
      "\n",
      "### Response Format (follow EXACTLY):\n",
      "1. Provide an explanation (1-2 paragraphs) of why you selected the intent. Be sure to consider two-to-three other intents before settling on a final choice.\n",
      "2. Then output the final predicted intent on a new line in the following format:\n",
      "\n",
      "Final Choice: <intent_label>\n",
      "\n",
      "Do NOT invent new intents.\n",
      "Do NOT output anything other than the two required parts.\n",
      "\n",
      "Begin.\n",
      "\n",
      "Explanation:\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Get the list of all unique intent classes from the full dataset\n",
    "all_unique_intents = df_synthetic['intent'].unique()\n",
    "all_unique_intents_sorted = sorted(all_unique_intents)\n",
    "# Format as a bulleted list for better LLM parsing\n",
    "all_unique_intents_bulleted = \"\\n- \" + \"\\n- \".join(all_unique_intents_sorted)\n",
    "\n",
    "print(f\"All unique intents available (formatted for prompt): {all_unique_intents_bulleted}\\n\")\n",
    "\n",
    "def create_zero_shot_prompt(category: str, instruction_synthetic: str, available_intents_bulleted: str) -> str:\n",
    "    \"\"\"\n",
    "    Constructs a zero-shot prompt for intent classification with controlled response format.\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = f'''You are an intent classification system.\n",
    "Your task is to classify the intent of a customer query.\n",
    "\n",
    "Specific guidelines (but not rules)\n",
    "\n",
    "Customers expecting a refund is not inherently getting a refund. They may be expecting one.\n",
    "Customers asking to check when their order will arrive are asking about the delivery period - unless an order number is apart of the instruction.\n",
    "Customers asking about possibility of orders are asking about delivery options, including where they are ordering from.\n",
    "Customers asking setting up a new or secondary address are not editing their address, but setting up an address.\n",
    "Customers looking to use a specific account (such as chequing and savings) or profile, are attempting to switch accounts.\n",
    "Customers looking customer assistance aren't inherently looking for human assistance.\n",
    "If an invoice has already been issued, and the customer is looking for it, that is check_invoice. \n",
    "Refund policy questions relate to check_refund_policy. Note that if they aren't asking for specifics on the policy, they are likely just wanting to get a refund.\n",
    "\n",
    "\n",
    "Customer Query Details:\n",
    "- Category: {category}\n",
    "- User Instruction: {instruction_synthetic}\n",
    "\n",
    "You MUST choose exactly one intent ONLY from the following list:\n",
    "\n",
    "Available Intents:\n",
    "{available_intents_bulleted}\n",
    "\n",
    "### Response Format (follow EXACTLY):\n",
    "1. Provide an explanation (1-2 paragraphs) of why you selected the intent. Be sure to consider two-to-three other intents before settling on a final choice.\n",
    "2. Then output the final predicted intent on a new line in the following format:\n",
    "\n",
    "Final Choice: <intent_label>\n",
    "\n",
    "Do NOT invent new intents.\n",
    "Do NOT output anything other than the two required parts.\n",
    "\n",
    "Begin.\n",
    "\n",
    "Explanation:'''\n",
    "    return prompt\n",
    "\n",
    "\n",
    "# Example usage with a sample from X_test_sampled\n",
    "if not X_test_sampled.empty:\n",
    "    sample_category = X_test_sampled['category'].iloc[0]\n",
    "    sample_instruction_synthetic = X_test_sampled['instruction_synthetic'].iloc[0]\n",
    "    example_prompt = create_zero_shot_prompt(sample_category, sample_instruction_synthetic, all_unique_intents_bulleted)\n",
    "    print(\"Example Zero-Shot Prompt (improved):\\n\")\n",
    "    print(example_prompt)\n",
    "else:\n",
    "    print(\"X_test_sampled is empty. Cannot generate an example prompt.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cad13a85"
   },
   "source": [
    "## Implement LLM Inference Function\n",
    "\n",
    "### Subtask:\n",
    "Provide a placeholder or example function that demonstrates how to make an LLM API call. This function will take a prompt and return the LLM's response. It will also include guidance for the user to insert their actual API key and handle the specific API integration for their chosen LLM, emphasizing careful usage to manage costs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-11-17T04:11:00.017668Z",
     "iopub.status.busy": "2025-11-17T04:11:00.017407Z",
     "iopub.status.idle": "2025-11-17T04:11:00.156351Z",
     "shell.execute_reply": "2025-11-17T04:11:00.155812Z",
     "shell.execute_reply.started": "2025-11-17T04:11:00.017649Z"
    },
    "id": "dae98a30",
    "outputId": "82c30b9d-a173-4593-ebe8-d8e7d5fdf21c",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import re\n",
    "from openai import OpenAI, APIError, RateLimitError\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "\n",
    "user_secrets = UserSecretsClient()\n",
    "OPENAI_API_KEY = user_secrets.get_secret(\"OPENAI_API_KEY\")\n",
    "\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "def safe_llm_predict(\n",
    "    prompt: str,\n",
    "    model_name: str = \"gpt-4.1-mini\",\n",
    "    timeout: int = 60,\n",
    "    max_retries: int = 6\n",
    "):\n",
    "\n",
    "    input_tokens = 0\n",
    "    output_tokens = 0\n",
    "    inference_time = 0.0\n",
    "    cost = 0.0\n",
    "    extracted_intent = \"LLM Error\"\n",
    "\n",
    "    for attempt in range(max_retries):\n",
    "        start_time = time.time()\n",
    "\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=model_name,\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                timeout=timeout\n",
    "            )\n",
    "\n",
    "            inference_time = time.time() - start_time\n",
    "\n",
    "            # FIXED: message is an object, not a dict\n",
    "            raw_text = response.choices[0].message.content.strip()\n",
    "\n",
    "            # usage handling\n",
    "            if response.usage:\n",
    "                input_tokens = response.usage.prompt_tokens or 0\n",
    "                output_tokens = response.usage.completion_tokens or 0\n",
    "\n",
    "\n",
    "            # Strong regex match\n",
    "            match = re.search(r\"Final\\s*Choice\\s*:\\s*([A-Za-z0-9_\\-]+)\",\n",
    "                              raw_text, flags=re.IGNORECASE)\n",
    "            if match:\n",
    "                extracted_intent = match.group(1).strip()\n",
    "                return extracted_intent, inference_time, input_tokens, output_tokens, cost\n",
    "\n",
    "            # Fallback: take final word after \"Final Choice:\"\n",
    "            match = re.search(r\"Final\\s*Choice\\s*:\\s*(.*)$\",\n",
    "                              raw_text, flags=re.IGNORECASE | re.DOTALL)\n",
    "            if match:\n",
    "                tail = match.group(1).strip()\n",
    "                last_word = re.findall(r\"[A-Za-z0-9_\\-]+\", tail)\n",
    "                if last_word:\n",
    "                    extracted_intent = last_word[-1]\n",
    "                    return extracted_intent, inference_time, input_tokens, output_tokens, cost\n",
    "\n",
    "            # Full fallback\n",
    "            fallback_tokens = re.findall(r\"[A-Za-z0-9_\\-]+\", raw_text)\n",
    "            if fallback_tokens:\n",
    "                extracted_intent = fallback_tokens[-1]\n",
    "\n",
    "            return extracted_intent, inference_time, input_tokens, output_tokens, cost\n",
    "\n",
    "        except RateLimitError:\n",
    "            wait_time = 1.5 ** attempt\n",
    "            print(f\"[429] Rate limit â€” retrying in {wait_time:.2f}s...\")\n",
    "            time.sleep(wait_time)\n",
    "            continue\n",
    "\n",
    "        except APIError as e:\n",
    "            return f\"LLM Error: {e}\", inference_time, input_tokens, output_tokens, cost\n",
    "\n",
    "        except Exception as e:\n",
    "            return f\"LLM Error: {e}\", inference_time, input_tokens, output_tokens, cost\n",
    "\n",
    "    return extracted_intent, inference_time, input_tokens, output_tokens, cost\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hA_p8CnhrNI9"
   },
   "source": [
    "Here's a breakdown of the output:\n",
    "\n",
    "\"Starting LLM inference for 270 samples... LLM inference completed.\": This confirms that the loop processed all 270 sampled test cases, generating a prediction for each one using the gemini-2.0-flash-lite model.\n",
    "\n",
    "\"Head of LLM Predictions:\"\n",
    "\n",
    "This displays the first few rows of the predictions_df DataFrame. You can see the original index of the sampled X_test examples and the corresponding llm_predicted_intent. For instance, you can see several change_order predictions at the top.\n",
    "\"Value counts of LLM Predictions:\"\n",
    "\n",
    "This is a crucial summary, showing the frequency of each intent predicted by the LLM across all 270 samples. Ideally, if the LLM was perfect and predicted correctly for all 10 samples of each of the 27 intents, we would see each unique intent listed with a count of 10. This output helps us quickly identify which intents the LLM is predicting more often, or if there are any unexpected predictions or errors.\n",
    "This output now gives us the LLM's zero-shot predictions, which we can compare against the true y_test_sampled labels to evaluate its performance!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T04:11:03.132058Z",
     "iopub.status.busy": "2025-11-17T04:11:03.131549Z",
     "iopub.status.idle": "2025-11-17T04:11:03.137315Z",
     "shell.execute_reply": "2025-11-17T04:11:03.136542Z",
     "shell.execute_reply.started": "2025-11-17T04:11:03.132037Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def test_safe_llm_predict(prompt: str):\n",
    "    \"\"\"\n",
    "    Direct test harness to inspect what the model returns\n",
    "    before running the full dataset loop.\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"\\n======================\")\n",
    "    print(\"ðŸ” TESTING LLM OUTPUT\")\n",
    "    print(\"======================\\n\")\n",
    "\n",
    "    # Make a single request\n",
    "    intent, inf_time, in_tokens, out_tokens, cost = safe_llm_predict(prompt)\n",
    "\n",
    "    print(\"ðŸ“Œ Extracted Intent:\", intent)\n",
    "    print(\"â±ï¸ Inference Time:\", inf_time)\n",
    "    print(\"ðŸ”¢ Input Tokens:\", in_tokens)\n",
    "    print(\"ðŸ”¢ Output Tokens:\", out_tokens)\n",
    "    print(\"ðŸ’² Cost:\", cost)\n",
    "\n",
    "    print(\"\\n--- RAW MODEL OUTPUT ---\\n\")\n",
    "\n",
    "    # Call the API *again* but without extraction\n",
    "    # so you can see EXACTLY what the model said\n",
    "    raw = client.chat.completions.create(\n",
    "        model=\"gpt-4.1-mini\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "\n",
    "    raw_text = raw.choices[0].message.content\n",
    "    print(raw_text)\n",
    "    print(\"\\n------------------------\\n\")\n",
    "\n",
    "    return raw_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T04:11:05.365733Z",
     "iopub.status.busy": "2025-11-17T04:11:05.365210Z",
     "iopub.status.idle": "2025-11-17T04:11:11.591518Z",
     "shell.execute_reply": "2025-11-17T04:11:11.590786Z",
     "shell.execute_reply.started": "2025-11-17T04:11:05.365712Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================\n",
      "ðŸ” TESTING LLM OUTPUT\n",
      "======================\n",
      "\n",
      "ðŸ“Œ Extracted Intent: change_order\n",
      "â±ï¸ Inference Time: 3.017700672149658\n",
      "ðŸ”¢ Input Tokens: 460\n",
      "ðŸ”¢ Output Tokens: 183\n",
      "ðŸ’² Cost: 0.0\n",
      "\n",
      "--- RAW MODEL OUTPUT ---\n",
      "\n",
      "Explanation:  \n",
      "The customer query explicitly states they want to \"swap an item\" from an existing order, which implies they want to modify or change something already ordered. This aligns closely with the intent \"change_order,\" as it involves adjusting the content of the order rather than canceling it altogether or merely tracking it. The query does mention a specific order number but does not request information about delivery periods or tracking, so \"delivery_period\" and \"track_order\" are less appropriate. Although the query involves an exchange, it does not mention refunds directly, so \"get_refund\" is unlikely. Therefore, the best fit is \"change_order\" as the customer wants to alter the items within an order.\n",
      "\n",
      "Final Choice: change_order\n",
      "\n",
      "------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Explanation:  \\nThe customer query explicitly states they want to \"swap an item\" from an existing order, which implies they want to modify or change something already ordered. This aligns closely with the intent \"change_order,\" as it involves adjusting the content of the order rather than canceling it altogether or merely tracking it. The query does mention a specific order number but does not request information about delivery periods or tracking, so \"delivery_period\" and \"track_order\" are less appropriate. Although the query involves an exchange, it does not mention refunds directly, so \"get_refund\" is unlikely. Therefore, the best fit is \"change_order\" as the customer wants to alter the items within an order.\\n\\nFinal Choice: change_order'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pick a sample row to test\n",
    "sample_row = X_test_sampled.iloc[0]\n",
    "\n",
    "test_prompt = create_zero_shot_prompt(\n",
    "    sample_row[\"category\"],\n",
    "    sample_row[\"instruction_synthetic\"],\n",
    "    all_unique_intents_bulleted\n",
    ")\n",
    "\n",
    "# Run the single test\n",
    "test_safe_llm_predict(test_prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T04:12:56.083630Z",
     "iopub.status.busy": "2025-11-17T04:12:56.082959Z",
     "iopub.status.idle": "2025-11-17T04:25:35.325955Z",
     "shell.execute_reply": "2025-11-17T04:25:35.325352Z",
     "shell.execute_reply.started": "2025-11-17T04:12:56.083608Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting LLM inference for 270 samples...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LLM Inference: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 270/270 [12:39<00:00,  2.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LLM inference completed.\n",
      "\n",
      "Head of LLM Predictions:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>llm_predicted_intent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1267</th>\n",
       "      <td>change_order</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1179</th>\n",
       "      <td>change_order</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1310</th>\n",
       "      <td>change_order</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048</th>\n",
       "      <td>change_order</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1950</th>\n",
       "      <td>change_order</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     llm_predicted_intent\n",
       "1267         change_order\n",
       "1179         change_order\n",
       "1310         change_order\n",
       "1048         change_order\n",
       "1950         change_order"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Value counts of LLM Predictions:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "llm_predicted_intent\n",
       "get_refund                  13\n",
       "contact_customer_service    11\n",
       "delivery_options            11\n",
       "check_invoice               11\n",
       "contact_human_agent         10\n",
       "change_order                10\n",
       "newsletter_subscription     10\n",
       "payment_issue               10\n",
       "delivery_period             10\n",
       "complaint                   10\n",
       "create_account              10\n",
       "delete_account              10\n",
       "switch_account              10\n",
       "set_up_shipping_address     10\n",
       "check_cancellation_fee      10\n",
       "cancel_order                10\n",
       "edit_account                10\n",
       "recover_password            10\n",
       "track_order                 10\n",
       "check_payment_methods       10\n",
       "change_shipping_address     10\n",
       "registration_problems       10\n",
       "review                       9\n",
       "place_order                  9\n",
       "get_invoice                  9\n",
       "check_refund_policy          9\n",
       "track_refund                 8\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "# Storage for metrics\n",
    "llm_predictions = []\n",
    "inference_times = []\n",
    "input_token_counts = []\n",
    "output_token_counts = []\n",
    "api_costs = []\n",
    "\n",
    "print(f\"Starting LLM inference for {len(X_test_sampled)} samples...\\n\")\n",
    "\n",
    "# tqdm progress bar\n",
    "for idx, row in tqdm(X_test_sampled.iterrows(), total=len(X_test_sampled), desc=\"LLM Inference\"):\n",
    "    category = row[\"category\"]\n",
    "    instruction_synthetic = row[\"instruction_synthetic\"]\n",
    "\n",
    "    # Build zero-shot prompt\n",
    "    prompt = create_zero_shot_prompt(\n",
    "        category,\n",
    "        instruction_synthetic,\n",
    "        all_unique_intents_bulleted\n",
    "    )\n",
    "\n",
    "    # Call LLM safely\n",
    "    prediction, inf_time, in_tokens, out_tokens, call_cost = safe_llm_predict(\n",
    "        prompt,\n",
    "        timeout=60\n",
    "    )\n",
    "\n",
    "    # Store metrics\n",
    "    llm_predictions.append(prediction)\n",
    "    inference_times.append(inf_time)\n",
    "    input_token_counts.append(in_tokens)\n",
    "    output_token_counts.append(out_tokens)\n",
    "    api_costs.append(call_cost)\n",
    "\n",
    "    # Slight delay to avoid rate limits\n",
    "    time.sleep(0.35)\n",
    "\n",
    "print(\"\\nLLM inference completed.\\n\")\n",
    "\n",
    "# Convert predictions to DataFrame\n",
    "predictions_df = pd.DataFrame(\n",
    "    {\"llm_predicted_intent\": llm_predictions},\n",
    "    index=X_test_sampled.index\n",
    ")\n",
    "\n",
    "print(\"Head of LLM Predictions:\")\n",
    "display(predictions_df.head())\n",
    "\n",
    "print(\"\\nValue counts of LLM Predictions:\")\n",
    "display(predictions_df[\"llm_predicted_intent\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T04:26:27.069349Z",
     "iopub.status.busy": "2025-11-17T04:26:27.068762Z",
     "iopub.status.idle": "2025-11-17T04:26:27.079100Z",
     "shell.execute_reply": "2025-11-17T04:26:27.078497Z",
     "shell.execute_reply.started": "2025-11-17T04:26:27.069328Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of wrong predictions: 7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_true</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>instruction_synthetic</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22042</th>\n",
       "      <td>review</td>\n",
       "      <td>contact_customer_service</td>\n",
       "      <td>need assistance leaving some feedback about yo...</td>\n",
       "      <td>FEEDBACK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26158</th>\n",
       "      <td>track_refund</td>\n",
       "      <td>get_refund</td>\n",
       "      <td>i expect a restitution of $50.00 dollars</td>\n",
       "      <td>REFUND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26327</th>\n",
       "      <td>track_refund</td>\n",
       "      <td>get_refund</td>\n",
       "      <td>i expect a rebate of $$50.00</td>\n",
       "      <td>REFUND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26265</th>\n",
       "      <td>track_refund</td>\n",
       "      <td>get_refund</td>\n",
       "      <td>i expect a compensqtion of $50.00 dollars</td>\n",
       "      <td>REFUND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15126</th>\n",
       "      <td>get_invoice</td>\n",
       "      <td>check_invoice</td>\n",
       "      <td>i have to download the invoices from Maria Garcia</td>\n",
       "      <td>INVOICE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19473</th>\n",
       "      <td>place_order</td>\n",
       "      <td>delivery_options</td>\n",
       "      <td>is it possible to acquire several of ur article</td>\n",
       "      <td>ORDER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6120</th>\n",
       "      <td>check_refund_policy</td>\n",
       "      <td>track_refund</td>\n",
       "      <td>can I check how long reimbursements usually take?</td>\n",
       "      <td>REFUND</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    y_true                    y_pred  \\\n",
       "22042               review  contact_customer_service   \n",
       "26158         track_refund                get_refund   \n",
       "26327         track_refund                get_refund   \n",
       "26265         track_refund                get_refund   \n",
       "15126          get_invoice             check_invoice   \n",
       "19473          place_order          delivery_options   \n",
       "6120   check_refund_policy              track_refund   \n",
       "\n",
       "                                   instruction_synthetic  category  \n",
       "22042  need assistance leaving some feedback about yo...  FEEDBACK  \n",
       "26158           i expect a restitution of $50.00 dollars    REFUND  \n",
       "26327                       i expect a rebate of $$50.00    REFUND  \n",
       "26265          i expect a compensqtion of $50.00 dollars    REFUND  \n",
       "15126  i have to download the invoices from Maria Garcia   INVOICE  \n",
       "19473    is it possible to acquire several of ur article     ORDER  \n",
       "6120   can I check how long reimbursements usually take?    REFUND  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build a dataframe with all relevant info\n",
    "results_df = pd.DataFrame({\n",
    "    \"y_true\": y_true,\n",
    "    \"y_pred\": y_pred,\n",
    "    \"instruction_synthetic\": X_test_sampled[\"instruction_synthetic\"].values,\n",
    "    \"category\": X_test_sampled[\"category\"].values\n",
    "})\n",
    "\n",
    "# Filter wrong predictions\n",
    "wrong_df = results_df[results_df[\"y_true\"] != results_df[\"y_pred\"]]\n",
    "\n",
    "print(\"Number of wrong predictions:\", len(wrong_df))\n",
    "wrong_df.head(27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-11-17T04:26:22.437490Z",
     "iopub.status.busy": "2025-11-17T04:26:22.436940Z",
     "iopub.status.idle": "2025-11-17T04:26:22.448831Z",
     "shell.execute_reply": "2025-11-17T04:26:22.448182Z",
     "shell.execute_reply.started": "2025-11-17T04:26:22.437469Z"
    },
    "id": "e06c720c",
    "outputId": "6363507e-6c68-405b-9409-ec82d718e1c7",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero-Shot LLM Performance:\n",
      "\n",
      "Accuracy: 0.9741\n",
      "Macro-F1 Score: 0.9739\n",
      "\n",
      "--- LLM Inference Metrics ---\n",
      "Total samples processed: 270\n",
      "Total inference time: 664.41 seconds\n",
      "Average inference time per sample: 2.4608 seconds\n",
      "Estimated inference time per 1000 samples: 2460.79 seconds\n",
      "Total input tokens consumed: 122311\n",
      "Total output tokens consumed: 40502\n",
      "Approximate API Cost for 270 samples: $0.000000\n",
      "Estimated API Cost per 1000 samples: $0.000000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# Ensure y_test_sampled and predictions_df are aligned by index\n",
    "y_true = y_test_sampled.loc[predictions_df.index]\n",
    "y_pred = predictions_df['llm_predicted_intent']\n",
    "\n",
    "# Calculate Accuracy\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "# Calculate Macro-F1 Score\n",
    "f1_macro = f1_score(y_true, y_pred, average='macro')\n",
    "\n",
    "print(f\"Zero-Shot LLM Performance:\\n\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Macro-F1 Score: {f1_macro:.4f}\")\n",
    "\n",
    "# Calculate and print additional metrics\n",
    "total_inference_time = sum(inference_times)\n",
    "average_time_per_sample = total_inference_time / len(X_test_sampled)\n",
    "estimated_time_per_1000_samples = average_time_per_sample * 1000\n",
    "\n",
    "total_input_tokens = sum(input_token_counts)\n",
    "total_output_tokens = sum(output_token_counts)\n",
    "total_api_cost = sum(api_costs)\n",
    "\n",
    "print(f\"\\n--- LLM Inference Metrics ---\")\n",
    "print(f\"Total samples processed: {len(X_test_sampled)}\")\n",
    "print(f\"Total inference time: {total_inference_time:.2f} seconds\")\n",
    "print(f\"Average inference time per sample: {average_time_per_sample:.4f} seconds\")\n",
    "print(f\"Estimated inference time per 1000 samples: {estimated_time_per_1000_samples:.2f} seconds\")\n",
    "print(f\"Total input tokens consumed: {total_input_tokens}\")\n",
    "print(f\"Total output tokens consumed: {total_output_tokens}\")\n",
    "print(f\"Approximate API Cost for {len(X_test_sampled)} samples: ${total_api_cost:.6f}\")\n",
    "print(f\"Estimated API Cost per 1000 samples: ${total_api_cost / len(X_test_sampled) * 1000:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T03:18:43.182784Z",
     "iopub.status.busy": "2025-11-17T03:18:43.182493Z",
     "iopub.status.idle": "2025-11-17T03:18:43.190767Z",
     "shell.execute_reply": "2025-11-17T03:18:43.189884Z",
     "shell.execute_reply.started": "2025-11-17T03:18:43.182765Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>flags</th>\n",
       "      <th>category</th>\n",
       "      <th>instruction_synthetic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1267</th>\n",
       "      <td>BLQZ</td>\n",
       "      <td>ORDER</td>\n",
       "      <td>i have got to swap  an item of order ORD-2025-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1179</th>\n",
       "      <td>BIL</td>\n",
       "      <td>ORDER</td>\n",
       "      <td>how do I correct purchase ORD-2025-12345?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1310</th>\n",
       "      <td>BILZ</td>\n",
       "      <td>ORDER</td>\n",
       "      <td>canm you help me to update purchase ORD-2025-1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048</th>\n",
       "      <td>BLMQ</td>\n",
       "      <td>ORDER</td>\n",
       "      <td>i try to switch several items of order ORD-202...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1950</th>\n",
       "      <td>BL</td>\n",
       "      <td>ORDER</td>\n",
       "      <td>I need information about correcting purchase O...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     flags category                              instruction_synthetic\n",
       "1267  BLQZ    ORDER  i have got to swap  an item of order ORD-2025-...\n",
       "1179   BIL    ORDER          how do I correct purchase ORD-2025-12345?\n",
       "1310  BILZ    ORDER  canm you help me to update purchase ORD-2025-1...\n",
       "1048  BLMQ    ORDER  i try to switch several items of order ORD-202...\n",
       "1950    BL    ORDER  I need information about correcting purchase O..."
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_sampled.head()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 4624298,
     "isSourceIdPinned": false,
     "sourceId": 7879155,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
